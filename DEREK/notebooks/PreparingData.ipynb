{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import maxabs_scale, MaxAbsScaler\n",
    "import anndata\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "# from model.stDiff_train import normal_train_stDiff\n",
    "sys.path.append('../..')\n",
    "from model.stDiff_model import DiT_stDiff\n",
    "from model.stDiff_scheduler import NoiseScheduler\n",
    "# from process.data import * \n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_data_path = '/Users/derekebowman/Coding Projects/stDiff/stDiff/DEREK/LiverFibrosisData/adata_healthy_diseased_merfish.h5ad'\n",
    "\n",
    "sequencing_data_path ='/Users/derekebowman/Coding Projects/stDiff/stDiff/DEREK/LiverFibrosisData/adata_healthy_diseased_nucseq.h5ad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_spatial = sc.read_h5ad(spatial_data_path)\n",
    "adata_seq = sc.read_h5ad(sequencing_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A2M', 'ABCA1', 'ABCA13', 'ABCB1', 'ABCB11', 'ABCC2', 'ABLIM1',\n",
       "       'AC007262.2', 'AC021242.2', 'ACMSD',\n",
       "       ...\n",
       "       'TTC7B', 'TXNRD1', 'UGT2B10', 'UGT2B4', 'VMP1', 'VSIG4', 'XDH',\n",
       "       'ZC3H13', 'ZNF483', 'ZSWIM6'],\n",
       "      dtype='object', length=317)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_spatial.var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ENSG00000238009', 'ENSG00000268903', 'ENSG00000241860',\n",
       "       'ENSG00000228463', 'ENSG00000290385', 'ENSG00000230021',\n",
       "       'ENSG00000291215', 'LINC01409', 'LINC00115', 'LINC01128',\n",
       "       ...\n",
       "       'ENSG00000230392', 'ENSG00000226661', 'STAG2-AS1', 'SH2D1A',\n",
       "       'LINC00629', 'PRRG3', 'LAGE3', 'ENSG00000224216', 'ENSG00000273906',\n",
       "       'MED14P1'],\n",
       "      dtype='object', length=24619)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_seq.var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_genes = adata_seq.var_names.intersection(adata_spatial.var_names)\n",
    "adata_sc = adata_seq[:, shared_genes]\n",
    "adata_sp = adata_spatial[:, shared_genes]\n",
    "\n",
    "# adata_sc.write(\"my_sequencing_data_shared_genes.h5ad\")\n",
    "#adata_sp.write(\"my_spatial_data_shared_genes.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(adata,  fixed: bool, noise_std):\n",
    "   \n",
    "    noise_stddev = noise_std\n",
    "    augmented_adata = adata.copy()\n",
    "    gene_expression = adata.X\n",
    "    \n",
    "    if fixed: \n",
    "        augmented_adata.X = augmented_adata.X + np.full(gene_expression.shape, noise_stddev)\n",
    "    else:\n",
    "        augmented_adata.X = augmented_adata.X + np.abs(np.random.normal(0, noise_stddev, gene_expression.shape))   \n",
    "    \n",
    "    merge_adata = adata.concatenate(augmented_adata, join='outer')\n",
    "    \n",
    "    \n",
    "    return merge_adata\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(adata):\n",
    "    scaler = MaxAbsScaler()\n",
    "    normalized_data = scaler.fit_transform(adata.X.T).T\n",
    "    adata.X = normalized_data\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_genes_spatial_path = '/Users/derekebowman/Coding Projects/stDiff/stDiff/DEREK/LiverFibrosisData/my_spatial_data_shared_genes.h5ad'\n",
    "shared_genes_sequencing_path = '/Users/derekebowman/Coding Projects/stDiff/stDiff/DEREK/LiverFibrosisData/my_sequencing_data_shared_genes.h5ad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_sequencing_shared= sc.read_h5ad(shared_genes_sequencing_path)\n",
    "adata_spatial_shared = sc.read_h5ad(shared_genes_spatial_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/anndata/_core/merge.py:847: FutureWarning: The default value of 'ignore' for the `na_action` parameter in pandas.Categorical.map is deprecated and will be changed to 'None' in a future version. Please set na_action to the desired value to avoid seeing this warning\n",
      "  concat_indices = concat_indices.str.cat(label_col.map(str), sep=index_unique)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/anndata/_core/merge.py:847: FutureWarning: The default value of 'ignore' for the `na_action` parameter in pandas.Categorical.map is deprecated and will be changed to 'None' in a future version. Please set na_action to the desired value to avoid seeing this warning\n",
      "  concat_indices = concat_indices.str.cat(label_col.map(str), sep=index_unique)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/anndata/_core/merge.py:847: FutureWarning: The default value of 'ignore' for the `na_action` parameter in pandas.Categorical.map is deprecated and will be changed to 'None' in a future version. Please set na_action to the desired value to avoid seeing this warning\n",
      "  concat_indices = concat_indices.str.cat(label_col.map(str), sep=index_unique)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    }
   ],
   "source": [
    "adata_seq2 = data_augment(adata_sequencing_shared.copy(), True, noise_std=10)\n",
    "adata_spatial2 = adata_spatial_shared.copy()\n",
    "\n",
    "sc.pp.normalize_total(adata_seq2, target_sum=1e4)\n",
    "sc.pp.log1p(adata_seq2)\n",
    "adata_seq2 = scale(adata_seq2) # stDiff need\n",
    "data_seq_array = adata_seq2.X\n",
    "\n",
    "sc.pp.normalize_total(adata_spatial2, target_sum=1e4)\n",
    "sc.pp.log1p(adata_spatial2)\n",
    "adata_spatial2 = scale(adata_spatial2)\n",
    "data_spatial_array = adata_spatial2.X\n",
    "\n",
    "sp_genes = np.array(adata_spatial2.var_names)\n",
    "sp_data = pd.DataFrame(data=data_spatial_array, columns=sp_genes)\n",
    "sc_data = pd.DataFrame(data=data_seq_array, columns=sp_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MIR34AHG</th>\n",
       "      <th>SLC25A33</th>\n",
       "      <th>STMN1</th>\n",
       "      <th>MFSD2A</th>\n",
       "      <th>CTPS1</th>\n",
       "      <th>SLFNL1</th>\n",
       "      <th>ECHDC2</th>\n",
       "      <th>SCP2</th>\n",
       "      <th>PLPP3</th>\n",
       "      <th>LEPR</th>\n",
       "      <th>...</th>\n",
       "      <th>VSIG4</th>\n",
       "      <th>TENM1</th>\n",
       "      <th>CD5L</th>\n",
       "      <th>AKR1B10</th>\n",
       "      <th>SCD</th>\n",
       "      <th>GATA1</th>\n",
       "      <th>ALAS2</th>\n",
       "      <th>CD8A</th>\n",
       "      <th>CD68</th>\n",
       "      <th>TBX21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.513306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513306</td>\n",
       "      <td>0.513306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513306</td>\n",
       "      <td>0.857922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513306</td>\n",
       "      <td>0.747640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.716956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.736251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.870800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.639469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.944683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724891</td>\n",
       "      <td>0.849329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.716296</td>\n",
       "      <td>0.620786</td>\n",
       "      <td>0.716296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620786</td>\n",
       "      <td>0.829525</td>\n",
       "      <td>0.716296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620786</td>\n",
       "      <td>0.620786</td>\n",
       "      <td>0.620786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575706</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.933522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.933522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575707</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.954444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575708</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575709</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575710</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575711 rows × 307 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MIR34AHG  SLC25A33     STMN1    MFSD2A     CTPS1    SLFNL1    ECHDC2  \\\n",
       "0       0.513306  0.000000  0.513306  0.513306  0.000000  0.513306  0.857922   \n",
       "1       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2       0.000000  0.000000  0.000000  0.639469  0.000000  0.000000  0.000000   \n",
       "3       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4       0.000000  0.620786  0.000000  0.000000  0.716296  0.620786  0.716296   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "575706  0.000000  0.000000  0.000000  0.000000  0.933522  0.000000  0.000000   \n",
       "575707  0.000000  0.954444  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "575708  0.000000  0.000000  0.000000  0.000000  1.000000  0.000000  0.000000   \n",
       "575709  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "575710  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        SCP2     PLPP3  LEPR  ...     VSIG4     TENM1      CD5L   AKR1B10  \\\n",
       "0        0.0  0.513306   0.0  ...  0.000000  0.000000  0.000000  0.513306   \n",
       "1        0.0  0.000000   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2        0.0  0.000000   0.0  ...  0.639469  0.000000  0.736251  0.000000   \n",
       "3        0.0  0.000000   0.0  ...  0.000000  0.000000  0.944683  0.000000   \n",
       "4        0.0  0.000000   0.0  ...  0.000000  0.000000  0.000000  0.620786   \n",
       "...      ...       ...   ...  ...       ...       ...       ...       ...   \n",
       "575706   0.0  0.000000   0.0  ...  0.000000  0.933522  0.000000  0.000000   \n",
       "575707   0.0  0.000000   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "575708   0.0  0.000000   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "575709   0.0  0.000000   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "575710   0.0  0.000000   0.0  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "             SCD     GATA1  ALAS2      CD8A      CD68     TBX21  \n",
       "0       0.747640  0.000000    0.0  0.716956  0.000000  0.676218  \n",
       "1       0.000000  0.875185    0.0  0.875185  0.000000  0.000000  \n",
       "2       0.870800  0.000000    0.0  0.000000  0.000000  0.639469  \n",
       "3       0.000000  0.000000    0.0  0.724891  0.849329  0.000000  \n",
       "4       0.829525  0.716296    0.0  0.620786  0.620786  0.620786  \n",
       "...          ...       ...    ...       ...       ...       ...  \n",
       "575706  0.000000  0.000000    0.0  0.000000  0.000000  0.000000  \n",
       "575707  0.000000  0.000000    0.0  0.000000  0.000000  0.000000  \n",
       "575708  0.000000  0.000000    0.0  0.000000  0.000000  0.000000  \n",
       "575709  0.000000  0.000000    0.0  0.000000  0.000000  0.000000  \n",
       "575710  0.000000  0.000000    0.0  0.000000  0.000000  0.000000  \n",
       "\n",
       "[575711 rows x 307 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(data_ary:np.ndarray, \n",
    "                    cell_type:np.ndarray, \n",
    "                    batch_size:int=512,\n",
    "                    is_shuffle:bool=True,\n",
    "                    ):\n",
    "       \n",
    "\n",
    "        data_tensor = torch.from_numpy(data_ary.astype(np.float32))\n",
    "        cell_type_tensor = torch.from_numpy(cell_type.astype(np.float32))\n",
    "        dataset = TensorDataset(data_tensor,cell_type_tensor)\n",
    "        generator = torch.Generator(device='cpu')\n",
    "        return DataLoader(\n",
    "                dataset, batch_size=batch_size, shuffle=is_shuffle, drop_last=False , generator=generator) #, generator=torch.Generator(device = 'cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modulate(x, shift, scale):\n",
    "\n",
    "    res = x * (1 + scale) + shift\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_train_stDiff(model,\n",
    "                 dataloader,\n",
    "                 lr: float = 1e-4,\n",
    "                 num_epoch: int = 1400,\n",
    "                 pred_type: str = 'noise',\n",
    "                 diffusion_step: int = 1000,\n",
    "                 device=torch.device('cuda:1'),\n",
    "                 is_tqdm: bool = True,\n",
    "                 is_tune: bool = False,\n",
    "                 mask = None):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        lr (float): learning rate \n",
    "        pred_type (str, optional): noise or x_0. Defaults to 'noise'.\n",
    "        diffusion_step (int, optional): timestep. Defaults to 1000.\n",
    "        device (_type_, optional): Defaults to torch.device('cuda:1').\n",
    "        is_tqdm (bool, optional): tqdm. Defaults to True.\n",
    "        is_tune (bool, optional):  ray tune. Defaults to False.\n",
    "\n",
    "    Raises:\n",
    "        NotImplementedError: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    noise_scheduler = NoiseScheduler(\n",
    "        num_timesteps=diffusion_step,\n",
    "        beta_schedule='cosine'\n",
    "    )\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0)\n",
    "\n",
    "    if is_tqdm:\n",
    "        t_epoch = tqdm(range(num_epoch), ncols=100)\n",
    "    else:\n",
    "        t_epoch = range(num_epoch)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in t_epoch:\n",
    "        epoch_loss = 0.\n",
    "        for i, (x, x_cond) in enumerate(dataloader): \n",
    "            x, x_cond = x.float().to(device), x_cond.float().to(device)\n",
    "            # celltype = celltype.to(device)\n",
    "\n",
    "            noise = torch.randn(x.shape).to(device)\n",
    "            timesteps = torch.randint(1, diffusion_step, (x.shape[0],)).long()\n",
    "\n",
    "            x_t = noise_scheduler.add_noise(x,\n",
    "                                            noise,\n",
    "                                            timesteps=timesteps)\n",
    "\n",
    "            mask = torch.tensor(mask).to(device)\n",
    "            x_noisy = x_t * (1 - mask) + x * mask\n",
    "\n",
    "            noise_pred = model(x_noisy, t=timesteps.to(device), y=x_cond) \n",
    "            # loss = criterion(noise_pred, noise)\n",
    "\n",
    "            loss = criterion(noise*(1-mask), noise_pred*(1-mask))\n",
    "\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # type: ignore\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss = epoch_loss / (i + 1)  # type: ignore\n",
    "        if is_tqdm:\n",
    "            t_epoch.set_postfix_str(f'{pred_type} loss:{epoch_loss:.5f}')  # type: ignore\n",
    "        if is_tune:\n",
    "            session.report({'loss': epoch_loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/100 [00:00<?, ?it/s]/var/folders/3v/fv2nh3dj3z9b9bkz4lcmhvq80000gn/T/ipykernel_75822/3308919336.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask = torch.tensor(mask).to(device)\n",
      "100%|█████████████████████████████████████████| 100/100 [13:07<00:00,  7.87s/it, noise loss:0.02830]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = 0.00016046744893538737 \n",
    "depth = 6 \n",
    "num_epoch = 100\n",
    "diffusion_step = 1500 \n",
    "batch_size = 2048 \n",
    "hidden_size = 512 \n",
    "head = 16\n",
    "\n",
    "# mask\n",
    "cell_num = data_spatial_array.shape[0]\n",
    "gene_num = data_spatial_array.shape[1]\n",
    "mask = np.ones((gene_num,), dtype='float32')\n",
    "\n",
    "# gene_id_test\n",
    "train_size = 0.8\n",
    "gene_names_rnaseq = sp_genes \n",
    "np.random.seed(0)\n",
    "n_genes = len(gene_names_rnaseq)\n",
    "gene_ids_train = sorted(\n",
    "    np.random.choice(range(n_genes), int(n_genes * train_size), False)\n",
    ")\n",
    "gene_ids_test = sorted(set(range(n_genes)) - set(gene_ids_train)) # test\n",
    "\n",
    "mask[gene_ids_test] = 0\n",
    "\n",
    "seq = data_seq_array\n",
    "st = data_spatial_array\n",
    "data_seq_masked = seq * mask\n",
    "data_spatial_masked = st * mask\n",
    "\n",
    "seq = seq * 2 - 1\n",
    "data_seq_masked = data_seq_masked * 2 - 1\n",
    "\n",
    "st = st * 2 - 1\n",
    "data_spatial_masked = data_spatial_masked * 2 - 1\n",
    "\n",
    "dataloader = get_data_loader(\n",
    "    seq, # all gene\n",
    "    data_seq_masked, # test gene = 0\n",
    "    batch_size=batch_size, \n",
    "    is_shuffle=True)\n",
    "\n",
    "seed = 1202\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "model = DiT_stDiff(\n",
    "    input_size=gene_num,  \n",
    "    hidden_size=hidden_size, \n",
    "    depth=depth,\n",
    "    num_heads=head,\n",
    "    classes=6, \n",
    "    mlp_ratio=4.0,\n",
    "    dit_type='dit'\n",
    ")\n",
    "\n",
    "device = torch.device('mps')\n",
    "model.to(device)\n",
    "\n",
    "diffusion_step = diffusion_step\n",
    "\n",
    "\n",
    "save_path_prefix = '/Users/derekebowman/Coding Projects/stDiff/stDiff/DEREK/example_results/demo.pt'\n",
    "\n",
    "# Ensure the target folder exists:\n",
    "os.makedirs(os.path.dirname(save_path_prefix), exist_ok=True)\n",
    "\n",
    "model.train()\n",
    "\n",
    "if not os.path.isfile(save_path_prefix):\n",
    "    normal_train_stDiff(\n",
    "        model,\n",
    "        dataloader=dataloader,\n",
    "        lr=lr,\n",
    "        num_epoch=num_epoch,\n",
    "        diffusion_step=diffusion_step,\n",
    "        device=device,\n",
    "        pred_type='noise',\n",
    "        mask=mask\n",
    "    )\n",
    "\n",
    "    torch.save(model.state_dict(), save_path_prefix)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(save_path_prefix, map_location=device))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion sampling (to imput the spatial gene values)\n",
    "\n",
    "From their demo below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.sample import sample_stDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time: 1496:   0%|          | 3/1500 [01:16<10:38:08, 25.58s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m get_data_loader(\n\u001b[1;32m      9\u001b[0m     data_spatial_masked, \u001b[38;5;66;03m# test gene = 0\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     data_spatial_masked, \u001b[38;5;66;03m# test gene = 0\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size, \n\u001b[1;32m     12\u001b[0m     is_shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 16\u001b[0m imputation \u001b[38;5;241m=\u001b[39m \u001b[43msample_stDiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mnoise_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mgt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mnum_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiffusion_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcell_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgene_num\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mis_condi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43msample_intermediate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiffusion_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmodel_pred_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnoise\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mis_classifier_guidance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43momega\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m data_spatial_masked[:, gene_ids_test] \u001b[38;5;241m=\u001b[39m imputation[:, gene_ids_test]\n\u001b[1;32m     32\u001b[0m impu \u001b[38;5;241m=\u001b[39m (data_spatial_masked  \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/Coding Projects/stDiff/stDiff/DEREK/notebooks/../../model/sample.py:71\u001b[0m, in \u001b[0;36msample_stDiff\u001b[0;34m(model, dataloader, noise_scheduler, mask, gt, device, num_step, sample_shape, is_condi, sample_intermediate, model_pred_type, is_classifier_guidance, omega)\u001b[0m\n\u001b[1;32m     68\u001b[0m ts\u001b[38;5;241m.\u001b[39mset_description_str(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 71\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_sample_stDiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtotal_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# x_t\u001b[39;49;00m\n\u001b[1;32m     75\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# t\u001b[39;49;00m\n\u001b[1;32m     76\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mis_condi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_condi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mcondi_flag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_classifier_guidance:\n\u001b[1;32m     79\u001b[0m         model_output_uncondi \u001b[38;5;241m=\u001b[39m model_sample_stDiff(model,\n\u001b[1;32m     80\u001b[0m                                             device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     81\u001b[0m                                             dataloader\u001b[38;5;241m=\u001b[39mdataloader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m                                             is_condi\u001b[38;5;241m=\u001b[39mis_condi,\n\u001b[1;32m     85\u001b[0m                                             condi_flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Coding Projects/stDiff/stDiff/DEREK/notebooks/../../model/sample.py:10\u001b[0m, in \u001b[0;36mmodel_sample_stDiff\u001b[0;34m(model, device, dataloader, total_sample, time, is_condi, condi_flag)\u001b[0m\n\u001b[1;32m      8\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, x_cond \u001b[38;5;129;01min\u001b[39;00m dataloader: \n\u001b[0;32m---> 10\u001b[0m     x_cond \u001b[38;5;241m=\u001b[39m \u001b[43mx_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     11\u001b[0m     t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39mrepeat(time, x_cond\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# celltype = celltype.to(device)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sample\n",
    "gt = data_spatial_masked\n",
    "noise_scheduler = NoiseScheduler(\n",
    "    num_timesteps=diffusion_step,\n",
    "    beta_schedule='cosine'\n",
    ")\n",
    "\n",
    "dataloader = get_data_loader(\n",
    "    data_spatial_masked, # test gene = 0\n",
    "    data_spatial_masked, # test gene = 0\n",
    "    batch_size=batch_size, \n",
    "    is_shuffle=False)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "imputation = sample_stDiff(model,\n",
    "                                    device=device,\n",
    "                                    dataloader=dataloader,\n",
    "                                    noise_scheduler=noise_scheduler,\n",
    "                                    mask=mask,\n",
    "                                    gt=gt,\n",
    "                                    num_step=diffusion_step,\n",
    "                                    sample_shape=(cell_num, gene_num),\n",
    "                                    is_condi=True,\n",
    "                                    sample_intermediate=diffusion_step,\n",
    "                                    model_pred_type='noise',\n",
    "                                    is_classifier_guidance=False,\n",
    "                                    omega=0.2)\n",
    "\n",
    "data_spatial_masked[:, gene_ids_test] = imputation[:, gene_ids_test]\n",
    "\n",
    "impu = (data_spatial_masked  + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********** metrics **********\n",
    "def imputation_metrics(original, imputed):\n",
    "    absolute_error = np.abs(original - imputed)\n",
    "    relative_error = absolute_error / np.maximum(\n",
    "        np.abs(original), np.ones_like(original)\n",
    "    )\n",
    "    spearman_gene = []\n",
    "    for g in range(imputed.shape[1]):\n",
    "        if np.all(imputed[:, g] == 0):\n",
    "            correlation = 0\n",
    "        else:\n",
    "            correlation = spearmanr(original[:, g], imputed[:, g])[0]\n",
    "        spearman_gene.append(correlation)\n",
    "\n",
    "    return {\n",
    "        \"median_absolute_error_per_gene\": np.median(absolute_error, axis=0),\n",
    "        \"mean_absolute_error_per_gene\": np.mean(absolute_error, axis=0),\n",
    "        \"mean_relative_error\": np.mean(relative_error, axis=1),\n",
    "        \"median_relative_error\": np.median(relative_error, axis=1),\n",
    "        \"spearman_per_gene\": np.array(spearman_gene),\n",
    "\n",
    "        # Metric we report in the GimVI paper:\n",
    "        \"median_spearman_per_gene\": np.median(spearman_gene),\n",
    "    }\n",
    "\n",
    "tmp = imputation_metrics(np.array(data_spatial_array[:, gene_ids_test]), impu[:, gene_ids_test])\n",
    "tmp['median_spearman_per_gene']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From ChatGPT to incorporate the full gene expression (after training the model on the shared genes)\n",
    "\n",
    "Perhaps filter for ligand-receptors only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use full scRNA-seq data, already normalized/logged/scaled\n",
    "adata_sc_full = adata_seq.copy()  # all 5000+ genes\n",
    "\n",
    "# For spatial data, include zeros for non-observed genes:\n",
    "extra_genes = adata_sc_full.var_names.difference(adata_spatial.var_names)\n",
    "zeros_array = np.zeros((adata_spatial.n_obs, len(extra_genes)))\n",
    "zeros_df = pd.DataFrame(zeros_array, columns=extra_genes, index=adata_spatial.obs_names)\n",
    "\n",
    "# Combine spatial data with zeros for extra genes\n",
    "full_spatial_df = pd.concat([adata_spatial.to_df(), zeros_df], axis=1)\n",
    "full_spatial_df = full_spatial_df[adata_sc_full.var_names]  # ensure matching order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune the model with the expanded data set, but:\n",
    "\n",
    "    Set original spatially-measured genes as observed (mask=1).\n",
    "    Set new genes as masked (mask=0) during training.\n",
    "\n",
    "(below:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones((adata_sc_full.n_vars,), dtype='float32')\n",
    "extra_gene_indices = [adata_sc_full.var_names.get_loc(g) for g in extra_genes]\n",
    "mask[extra_gene_indices] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain (normal_train_stDiff) briefly with lower learning rate on the expanded dataset to learn the relationship of these new genes to spatial anchor genes.\n",
    "\n",
    "Perform diffusion sampling (sample_stDiff) as usual to impute missing spatial values for all genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your model with expanded gene number (full dataset)\n",
    "model_full = DiT_stDiff(\n",
    "    input_size=adata_sc_full.n_vars,  # full 5000+ genes\n",
    "    hidden_size=hidden_size, \n",
    "    depth=depth,\n",
    "    num_heads=head,\n",
    "    classes=6, \n",
    "    mlp_ratio=4.0,\n",
    "    dit_type='dit'\n",
    ")\n",
    "\n",
    "device = torch.device('mps')\n",
    "model_full.to(device)\n",
    "\n",
    "# Load pretrained weights (for shared genes only)\n",
    "pretrained_state_dict = torch.load(save_path_prefix, map_location=device)\n",
    "\n",
    "# Carefully load shared weights into expanded model\n",
    "model_dict = model_full.state_dict()\n",
    "shared_keys = {k: v for k, v in pretrained_state_dict.items() if k in model_dict}\n",
    "model_dict.update(shared_keys)\n",
    "model_full.load_state_dict(model_dict)\n",
    "\n",
    "# Fine-tune (briefly retrain with lower lr, e.g., lr / 10)\n",
    "normal_train_stDiff(\n",
    "    model_full,\n",
    "    dataloader=new_dataloader,  # expanded dataloader including extra genes\n",
    "    lr=lr / 10,                 # smaller learning rate for fine-tuning\n",
    "    num_epoch=100,              # fewer epochs for fine-tuning\n",
    "    diffusion_step=diffusion_step,\n",
    "    device=device,\n",
    "    pred_type='noise',\n",
    "    mask=new_mask               # mask includes zeros for extra genes\n",
    ")\n",
    "\n",
    "# Save fine-tuned model\n",
    "fine_tuned_path = '/Users/derekebowman/Coding Projects/stDiff/stDiff/DEREK/example_results/fine_tuned_full_genes.pt'\n",
    "torch.save(model_full.state_dict(), fine_tuned_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fine-tuned model parameters\n",
    "model_full.load_state_dict(torch.load(fine_tuned_path, map_location=device))\n",
    "model_full.eval()\n",
    "\n",
    "# Sampling and imputation (use expanded dataloader and mask)\n",
    "imputation = sample_stDiff(\n",
    "    model_full,\n",
    "    device=device,\n",
    "    dataloader=new_dataloader,\n",
    "    noise_scheduler=noise_scheduler,\n",
    "    mask=new_mask,\n",
    "    gt=full_spatial_array,  # expanded array with zeros for extra genes\n",
    "    num_step=diffusion_step,\n",
    "    sample_shape=(cell_num, adata_sc_full.n_vars),\n",
    "    is_condi=True,\n",
    "    sample_intermediate=diffusion_step,\n",
    "    model_pred_type='noise',\n",
    "    is_classifier_guidance=False,\n",
    "    omega=0.2\n",
    ")\n",
    "\n",
    "# The 'imputation' array now includes spatial predictions for ALL genes (shared + extra)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
